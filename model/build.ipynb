{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa==0.6.2 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (0.6.2)\n",
      "Requirement already satisfied: six>=1.3 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (1.16.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (5.1.1)\n",
      "Requirement already satisfied: joblib>=0.12 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (1.1.1)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (0.4.2)\n",
      "Requirement already satisfied: numba>=0.38.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (0.56.4)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (1.10.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (3.0.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from librosa==0.6.2) (1.23.5)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from numba>=0.38.0->librosa==0.6.2) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from numba>=0.38.0->librosa==0.6.2) (65.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/skylerestavillo/opt/anaconda3/envs/rizz/lib/python3.9/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.6.2) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import soundfile as sf\n",
    "import json\n",
    "\n",
    "import librosa, os\n",
    "if librosa.__version__ != '0.6.2':\n",
    "    os.system('pip3 install librosa==0.6.2')\n",
    "    import librosa\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loop through .wav files and their corresponding .json files\n",
    "data_path_caller = \"data/audio/caller/\"\n",
    "data_path_agent = \"data/audio/agent/\"\n",
    "transcript_path = \"data/transcript/\"\n",
    "\n",
    "all_wav_files_caller = [f for f in os.listdir(data_path_caller) if f.endswith(\".wav\")]\n",
    "\n",
    "# Select 100 random samples\n",
    "wav_files_caller = random.sample(all_wav_files_caller, 3)\n",
    "\n",
    "# Use the same filenames for the agent audio files\n",
    "wav_files_agent = wav_files_caller\n",
    "\n",
    "json_files = [f.replace(\".wav\", \".json\") for f in wav_files_caller]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make function to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract acoustic features\n",
    "def extract_acoustic_features(audio_file, start_time, end_time):\n",
    "    y, sr = librosa.load(audio_file, sr=None, offset=start_time, duration=end_time - start_time)\n",
    "    \n",
    "    target_sr = 4000\n",
    "    if sr > target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "    \n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "    energy = np.mean(librosa.feature.rms(y=y))\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "    spectral_spread = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "    \n",
    "    try:\n",
    "        pitch = np.mean(librosa.feature.tonnetz(y=y, sr=sr))\n",
    "    except librosa.util.exceptions.ParameterError:\n",
    "        pitch = np.nan\n",
    "    \n",
    "    try:\n",
    "        spectral_entropy = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr))\n",
    "    except librosa.util.exceptions.ParameterError:\n",
    "        spectral_entropy = np.nan\n",
    "    \n",
    "    return zcr, energy, spectral_centroid, spectral_spread, pitch, spectral_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe audio with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Transcribe audio using Whisper\n",
    "import librosa.output\n",
    "model = whisper.load_model(\"base.en\")\n",
    "\n",
    "def transcribe_audio_whisper(audio_file, start_time, end_time):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file, sr=None, offset=start_time, duration=end_time - start_time)\n",
    "    \n",
    "     # Save the segmented audio to a temporary file\n",
    "    temp_file = \"temp.wav\"\n",
    "    librosa.output.write_wav(temp_file, y, sr)\n",
    "    \n",
    "    # Implement actual Whisper transcription here\n",
    "    transcript = model.transcribe(temp_file)\n",
    "    \n",
    "    # Remove the temporary file\n",
    "    os.remove(temp_file)\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Extract linguistic features using Word2Vec, GloVe, and BERT (replace with actual feature extraction code)\n",
    "def extract_linguistic_features(transcript):\n",
    "    # Implement actual linguistic feature extraction here\n",
    "    return \"word2vec_features\", \"glove_features\", \"bert_features\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform acoustic feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing: 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'soundfile' has no attribute 'SoundFileRuntimeError'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/rizz/lib/python3.9/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rizz/lib/python3.9/site-packages/librosa/core/audio.py:215\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m offset:\n\u001b[1;32m    214\u001b[0m     \u001b[39m# Seek to the start of the target read\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     sf_desc\u001b[39m.\u001b[39;49mseek(\u001b[39mint\u001b[39;49m(offset \u001b[39m*\u001b[39;49m sr_native))\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m duration \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rizz/lib/python3.9/site-packages/soundfile.py:870\u001b[0m, in \u001b[0;36mSoundFile.seek\u001b[0;34m(self, frames, whence)\u001b[0m\n\u001b[1;32m    869\u001b[0m position \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_seek(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file, frames, whence)\n\u001b[0;32m--> 870\u001b[0m _error_check(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_errorcode)\n\u001b[1;32m    871\u001b[0m \u001b[39mreturn\u001b[39;00m position\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rizz/lib/python3.9/site-packages/soundfile.py:1455\u001b[0m, in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1454\u001b[0m err_str \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error_number(err)\n\u001b[0;32m-> 1455\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(prefix \u001b[39m+\u001b[39m _ffi\u001b[39m.\u001b[39mstring(err_str)\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Internal psf_fseek() failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m end_time \u001b[39m=\u001b[39m (offset_ms \u001b[39m+\u001b[39m duration_ms) \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m     17\u001b[0m acoustic_features_caller \u001b[39m=\u001b[39m extract_acoustic_features(data_path_caller \u001b[39m+\u001b[39m wav_file_caller, start_time, end_time)\n\u001b[0;32m---> 18\u001b[0m acoustic_features_agent \u001b[39m=\u001b[39m extract_acoustic_features(data_path_agent \u001b[39m+\u001b[39;49m wav_file_agent, start_time, end_time)\n\u001b[1;32m     20\u001b[0m whisper_transcript \u001b[39m=\u001b[39m transcribe_audio_whisper(data_path_caller \u001b[39m+\u001b[39m wav_file_caller, start_time, end_time)\n\u001b[1;32m     21\u001b[0m word2vec_features, glove_features, bert_features \u001b[39m=\u001b[39m extract_linguistic_features(whisper_transcript)\n",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m, in \u001b[0;36mextract_acoustic_features\u001b[0;34m(audio_file, start_time, end_time)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_acoustic_features\u001b[39m(audio_file, start_time, end_time):\n\u001b[0;32m----> 3\u001b[0m     y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(audio_file, sr\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, offset\u001b[39m=\u001b[39;49mstart_time, duration\u001b[39m=\u001b[39;49mend_time \u001b[39m-\u001b[39;49m start_time)\n\u001b[1;32m      5\u001b[0m     target_sr \u001b[39m=\u001b[39m \u001b[39m4000\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m sr \u001b[39m>\u001b[39m target_sr:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rizz/lib/python3.9/site-packages/librosa/core/audio.py:178\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m--> 178\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39;49mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    181\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    182\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    183\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'soundfile' has no attribute 'SoundFileRuntimeError'"
     ]
    }
   ],
   "source": [
    "# 4. Extract acoustic features and create data\n",
    "data = []\n",
    "count = 0  # Initialize the counter\n",
    "\n",
    "for wav_file_caller, wav_file_agent, json_file in zip(wav_files_caller, wav_files_agent, json_files):\n",
    "    with open(transcript_path + json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    human_transcripts = [entry[\"human_transcript\"] for entry in json_data if entry[\"human_transcript\"] != \"[noise]\"]\n",
    "    emotion_scores = [entry[\"emotion\"] for entry in json_data if entry[\"human_transcript\"] != \"[noise]\"]\n",
    "    offset_durations = [(entry[\"offset_ms\"], entry[\"duration_ms\"]) for entry in json_data if entry[\"human_transcript\"] != \"[noise]\"]\n",
    "\n",
    "    for transcript, emotion_score, (offset_ms, duration_ms) in zip(human_transcripts, emotion_scores, offset_durations):\n",
    "        start_time = offset_ms / 1000\n",
    "        end_time = (offset_ms + duration_ms) / 1000\n",
    "\n",
    "        acoustic_features_caller = extract_acoustic_features(data_path_caller + wav_file_caller, start_time, end_time)\n",
    "        acoustic_features_agent = extract_acoustic_features(data_path_agent + wav_file_agent, start_time, end_time)\n",
    "\n",
    "        whisper_transcript = transcribe_audio_whisper(data_path_caller + wav_file_caller, start_time, end_time)\n",
    "        word2vec_features, glove_features, bert_features = extract_linguistic_features(whisper_transcript)\n",
    "\n",
    "        row = (wav_file_caller, wav_file_agent, transcript, whisper_transcript, word2vec_features, glove_features, bert_features, *acoustic_features_caller, *acoustic_features_agent, emotion_score)\n",
    "        data.append(row)\n",
    "\n",
    "    count += 1  # Increment the counter\n",
    "    print(f\"Finished processing: {count}\")  # Print the current progress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Export data to a CSV file\n",
    "column_names = [\"CallerAudio\", \"AgentAudio\", \"Transcript\", \"WhisperTranscript\", \"Word2Vec\", \"GloVe\", \"BERT\", \"CallerZCR\", \"CallerEnergy\", \"CallerSpectralCentroid\", \"CallerSpectralSpread\", \"CallerPitch\", \"CallerSpectralEntropy\", \"AgentZCR\", \"AgentEnergy\", \"AgentSpectralCentroid\", \"AgentSpectralSpread\", \"AgentPitch\", \"AgentSpectralEntropy\", \"EmotionScore\"]\n",
    "df = pd.DataFrame(data, columns=column_names)\n",
    "df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rizz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "feb107a098849b32906f855eda7b629f34d4fe10c2185e28497f1608518d1332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
